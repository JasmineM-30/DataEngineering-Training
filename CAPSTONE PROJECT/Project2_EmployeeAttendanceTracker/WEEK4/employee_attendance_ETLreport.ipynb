{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cb5d66a5-7df0-4e7d-8948-4b3c917ad1b5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>department</th><th>date</th><th>avg_workhours</th><th>avg_taskscompleted</th><th>total_late_logins</th><th>total_absences</th><th>late_login_ratio</th><th>absence_ratio</th></tr></thead><tbody><tr><td>Finance</td><td>null</td><td>null</td><td>null</td><td>0</td><td>1</td><td>0.0</td><td>1.0</td></tr><tr><td>Finance</td><td>2025-09-10</td><td>8.0</td><td>2.0</td><td>0</td><td>0</td><td>0.0</td><td>0.0</td></tr><tr><td>HR</td><td>2025-09-10</td><td>8.5</td><td>4.0</td><td>0</td><td>0</td><td>0.0</td><td>0.0</td></tr><tr><td>HR</td><td>2025-09-11</td><td>8.666666666666666</td><td>5.0</td><td>0</td><td>0</td><td>0.0</td><td>0.0</td></tr><tr><td>IT</td><td>2025-09-10</td><td>8.75</td><td>4.0</td><td>0</td><td>0</td><td>0.0</td><td>0.0</td></tr><tr><td>IT</td><td>2025-09-11</td><td>8.333333333333334</td><td>4.0</td><td>0</td><td>0</td><td>0.0</td><td>0.0</td></tr><tr><td>Marketing</td><td>null</td><td>null</td><td>null</td><td>0</td><td>1</td><td>0.0</td><td>1.0</td></tr><tr><td>Marketing</td><td>2025-09-10</td><td>8.166666666666666</td><td>2.0</td><td>0</td><td>0</td><td>0.0</td><td>0.0</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "Finance",
         null,
         null,
         null,
         0,
         1,
         0.0,
         1.0
        ],
        [
         "Finance",
         "2025-09-10",
         8.0,
         2.0,
         0,
         0,
         0.0,
         0.0
        ],
        [
         "HR",
         "2025-09-10",
         8.5,
         4.0,
         0,
         0,
         0.0,
         0.0
        ],
        [
         "HR",
         "2025-09-11",
         8.666666666666666,
         5.0,
         0,
         0,
         0.0,
         0.0
        ],
        [
         "IT",
         "2025-09-10",
         8.75,
         4.0,
         0,
         0,
         0.0,
         0.0
        ],
        [
         "IT",
         "2025-09-11",
         8.333333333333334,
         4.0,
         0,
         0,
         0.0,
         0.0
        ],
        [
         "Marketing",
         null,
         null,
         null,
         0,
         1,
         0.0,
         1.0
        ],
        [
         "Marketing",
         "2025-09-10",
         8.166666666666666,
         2.0,
         0,
         0,
         0.0,
         0.0
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "department",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "date",
         "type": "\"date\""
        },
        {
         "metadata": "{}",
         "name": "avg_workhours",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "avg_taskscompleted",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "total_late_logins",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "total_absences",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "late_login_ratio",
         "type": "\"double\""
        },
        {
         "metadata": "{}",
         "name": "absence_ratio",
         "type": "\"double\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved department monthly metrics to Delta at dbfs:/FileStore/tables/department_monthly_metrics_delta\nSaved department monthly metrics CSVs at dbfs:/FileStore/tables/department_monthly_metrics_csv\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, to_timestamp, trim, when, hour, avg, sum\n",
    "\n",
    "# === Step 1: Load employee attendance CSV ===\n",
    "attendance_path = \"dbfs:/FileStore/tables/attendance_clean.csv\"\n",
    "\n",
    "attendance_df = spark.read.option(\"header\", True).option(\"inferSchema\", True).csv(attendance_path)\n",
    "\n",
    "# === Step 2: Clean and transform attendance data ===\n",
    "attendance_df_clean = attendance_df \\\n",
    "    .withColumn(\"clockin\", to_timestamp(col(\"clockin\"))) \\\n",
    "    .withColumn(\"clockout\", to_timestamp(col(\"clockout\"))) \\\n",
    "    .withColumn(\"status\", trim(col(\"status\"))) \\\n",
    "    .withColumn(\"is_late\", when(hour(\"clockin\") > 9, 1)\n",
    "                .when((hour(\"clockin\") == 9) & (col(\"clockin\").substr(15, 2).cast(\"int\") > 30), 1)\n",
    "                .otherwise(0)) \\\n",
    "    .withColumn(\"is_absent\", when(col(\"status\").rlike(\"(?i)absent\"), 1).otherwise(0)) \\\n",
    "    .withColumn(\"workhours\", (col(\"clockout\").cast(\"long\") - col(\"clockin\").cast(\"long\")) / 3600) \\\n",
    "    .withColumn(\"taskscompleted\", col(\"taskscompleted\").cast(\"int\"))\n",
    "\n",
    "# === Step 3: Aggregate department-level monthly KPIs ===\n",
    "# Assuming your attendance CSV includes a date column or use the date part of clockin\n",
    "attendance_df_clean = attendance_df_clean.withColumn(\"date\", to_timestamp(col(\"clockin\")).cast(\"date\"))\n",
    "\n",
    "dept_monthly_metrics = attendance_df_clean.groupBy(\"department\", \"date\").agg(\n",
    "    avg(\"workhours\").alias(\"avg_workhours\"),\n",
    "    avg(\"taskscompleted\").alias(\"avg_taskscompleted\"),\n",
    "    sum(\"is_late\").alias(\"total_late_logins\"),\n",
    "    sum(\"is_absent\").alias(\"total_absences\"),\n",
    "    avg(\"is_late\").alias(\"late_login_ratio\"),\n",
    "    avg(\"is_absent\").alias(\"absence_ratio\")\n",
    ")\n",
    "\n",
    "# === Step 4: Display aggregated KPIs ===\n",
    "display(dept_monthly_metrics.orderBy(\"department\", \"date\"))\n",
    "\n",
    "# === Step 5: Save outputs as Delta and CSV for dashboard use ===\n",
    "delta_output_path = \"dbfs:/FileStore/tables/department_monthly_metrics_delta\"\n",
    "csv_output_path = \"dbfs:/FileStore/tables/department_monthly_metrics_csv\"\n",
    "\n",
    "dept_monthly_metrics.write.format(\"delta\").mode(\"overwrite\").save(delta_output_path)\n",
    "dept_monthly_metrics.write.option(\"header\", True).mode(\"overwrite\").csv(csv_output_path)\n",
    "\n",
    "# === Step 6: Register Delta table ===\n",
    "spark.sql(f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS department_monthly_metrics\n",
    "USING DELTA\n",
    "\"\"\")\n",
    "\n",
    "print(f\"Saved department monthly metrics to Delta at {delta_output_path}\")\n",
    "print(f\"Saved department monthly metrics CSVs at {csv_output_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "employee_attendance_ETLreport",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}